import 'dart:io';
import 'package:dio/dio.dart';
import 'package:flutter/foundation.dart';
import 'package:alimenta_ai/config/openai_config.dart';

class OpenAIService {
  static const String _baseUrl = 'https://api.openai.com/v1';
  static String _apiKey = OpenAIConfig.apiKey;

  final Dio _dio = Dio();

  OpenAIService() {
    _dio.options.baseUrl = _baseUrl;
    _dio.options.headers = {
      'Authorization': 'Bearer $_apiKey',
      'Content-Type': 'multipart/form-data',
    };
    _dio.options.connectTimeout = OpenAIConfig.connectTimeout;
    _dio.options.receiveTimeout = OpenAIConfig.receiveTimeout;
  }

  /// Transcreve um arquivo de √°udio usando o Whisper da OpenAI
  Future<String?> transcribeAudio(String audioFilePath) async {
    try {
      debugPrint('üéØ Iniciando transcri√ß√£o do √°udio: $audioFilePath');

      // Para web, tratar de forma diferente
      if (kIsWeb) {
        return await _transcribeAudioWeb(audioFilePath);
      }

      // Para plataformas nativas
      final file = File(audioFilePath);
      if (!file.existsSync()) {
        debugPrint('‚ùå Arquivo de √°udio n√£o encontrado: $audioFilePath');
        return null;
      }

      // Verificar tamanho do arquivo
      final fileSize = await file.length();
      debugPrint('üìä Tamanho do arquivo: ${fileSize} bytes');

      if (fileSize == 0) {
        debugPrint('‚ùå Arquivo de √°udio est√° vazio');
        return null;
      }

      // Preparar o FormData
      final formData = FormData.fromMap({
        'file': await MultipartFile.fromFile(
          audioFilePath,
          filename: 'audio.wav',
          contentType: DioMediaType('audio', 'wav'),
        ),
        'model': OpenAIConfig.model,
        'language': OpenAIConfig.language,
        'response_format': 'text',
        'temperature': OpenAIConfig.temperature,
      });

      debugPrint('üöÄ Enviando √°udio para OpenAI Whisper...');

      // Fazer a requisi√ß√£o
      final response = await _dio.post(
        '/audio/transcriptions',
        data: formData,
      );

      if (response.statusCode == 200) {
        final transcription = response.data.toString().trim();
        debugPrint('‚úÖ Transcri√ß√£o recebida: $transcription');
        return transcription;
      } else {
        debugPrint('‚ùå Erro na resposta da API: ${response.statusCode}');
        debugPrint('Resposta: ${response.data}');
        return null;
      }
    } on DioException catch (e) {
      debugPrint('‚ùå Erro DioException na transcri√ß√£o:');
      debugPrint('Tipo: ${e.type}');
      debugPrint('Mensagem: ${e.message}');
      debugPrint('Response: ${e.response?.data}');
      return null;
    } catch (e) {
      debugPrint('‚ùå Erro inesperado na transcri√ß√£o: $e');
      return null;
    }
  }

  /// Transcri√ß√£o espec√≠fica para web
  Future<String?> _transcribeAudioWeb(String audioFilePath) async {
    try {
      debugPrint('üåê Processando √°udio para web: $audioFilePath');

      // TODO: Implementar suporte para web se necess√°rio
      // Por enquanto, retornar erro amig√°vel
      debugPrint('‚ùå Transcri√ß√£o n√£o suportada na web no momento');
      return 'Transcri√ß√£o n√£o suportada na plataforma web. Use em dispositivo m√≥vel ou desktop.';
    } catch (e) {
      debugPrint('‚ùå Erro na transcri√ß√£o web: $e');
      return null;
    }
  }

  /// Transcreve um arquivo de √°udio com resposta detalhada (JSON)
  Future<Map<String, dynamic>?> transcribeAudioDetailed(
      String audioFilePath) async {
    try {
      debugPrint('üéØ Iniciando transcri√ß√£o detalhada do √°udio: $audioFilePath');

      final file = File(audioFilePath);
      if (!file.existsSync()) {
        debugPrint('‚ùå Arquivo de √°udio n√£o encontrado: $audioFilePath');
        return null;
      }
      final formData = FormData.fromMap({
        'file': await MultipartFile.fromFile(
          audioFilePath,
          filename: 'audio.wav',
        ),
        'model': OpenAIConfig.model,
        'language': OpenAIConfig.language,
        'response_format': 'verbose_json', // Retorna JSON detalhado
        'temperature': OpenAIConfig.temperature,
        'timestamp_granularities[]': 'word', // Timestamps por palavra
      });

      debugPrint('üöÄ Enviando √°udio para OpenAI Whisper (modo detalhado)...');

      final response = await _dio.post(
        '/audio/transcriptions',
        data: formData,
      );

      if (response.statusCode == 200) {
        final result = response.data as Map<String, dynamic>;
        debugPrint('‚úÖ Transcri√ß√£o detalhada recebida');
        return result;
      } else {
        debugPrint('‚ùå Erro na resposta da API: ${response.statusCode}');
        return null;
      }
    } catch (e) {
      debugPrint('‚ùå Erro na transcri√ß√£o detalhada: $e');
      return null;
    }
  }

  /// Atualizar a API key (para configura√ß√£o din√¢mica)
  void updateApiKey(String newApiKey) {
    _apiKey = newApiKey;
    _dio.options.headers['Authorization'] = 'Bearer $_apiKey';
    debugPrint('üîë API Key atualizada no OpenAI Service');
  }

  /// Verificar se a API key est√° configurada
  bool get isApiKeyConfigured {
    return _apiKey.isNotEmpty && _apiKey != 'YOUR_OPENAI_API_KEY';
  }
}
